---
title: "Mistral AI"
date: 2023-12-30
---

Im currently learning how to create an additive training pipeline for the new Mixtral-8x7B-v0.1 model running pytorch on my GPU. Updated 2024-01-10: I got Mistral running on local device using cuda to thread on my GPU instead of CPU! Training this large of a model is out of scope without cloud computing resources though. My next post details a smaller 1.1B parameter LLM I created a demo for and trained locally as well!

